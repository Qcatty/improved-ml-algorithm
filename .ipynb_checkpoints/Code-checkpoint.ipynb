{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d499751",
   "metadata": {},
   "source": [
    "# Predicting ground states for 2D Heisenberg models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7de9d923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic functionalities\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import ast\n",
    "import datetime as dt\n",
    "from timeit import default_timer as timer\n",
    "from os import path\n",
    "\n",
    "# Neural tangent kernel\n",
    "import jax\n",
    "from neural_tangents import stax\n",
    "\n",
    "# Traditional ML methods and techniques\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d17dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "length = 6 # length = 4, 5, 6, 7, 8, 9 for orig; only 4, 5, 6, 7 for new\n",
    "width = 5\n",
    "\n",
    "shadow_size = 500 # up to 1000\n",
    "\n",
    "Xfull = [] # Shape = (number of data) x (number of params)\n",
    "Ytrain = [] # Shape = (number of data) x (number of pairs), estimated 2-point correlation functions\n",
    "Yfull = [] # Shape = (number of data) x (number of pairs), exact 2-point correlation functions\n",
    "\n",
    "def get_path_prefix(data='orig'):\n",
    "    prefix = './heisenberg_data/heisenberg_{}x{}'.format(length, width)\n",
    "    if data == 'new':\n",
    "        prefix = './new_data/data_{}x{}/simulation_{}x{}'.format(length, width, length, width)\n",
    "    return prefix\n",
    "    \n",
    "data_name = 'orig'\n",
    "prefix = get_path_prefix(data=data_name)\n",
    "\n",
    "for idx in range(1, 301):\n",
    "    if path.exists('{}_id{}_XX.txt'.format(prefix, idx)) == False:\n",
    "        continue\n",
    "    with open('{}_id{}_samples.txt'.format(prefix, idx), 'r') as f:\n",
    "        single_data = []\n",
    "        classical_shadow_big = [[int(c) for i, c in enumerate(line.split(\"\\t\"))] for line in f]\n",
    "        classical_shadow = classical_shadow_big[0:shadow_size]\n",
    "        for i in range(length * 5):\n",
    "            for j in range(length * 5):\n",
    "                if i == j:\n",
    "                    single_data.append(1.0)\n",
    "                    continue\n",
    "                corr = 0\n",
    "                cnt = 0\n",
    "                for shadow in classical_shadow:\n",
    "                    if shadow[i] // 2 == shadow[j] // 2:\n",
    "                        corr += 3 if shadow[i] % 2 == shadow[j] % 2 else -3\n",
    "                    cnt += 1\n",
    "                single_data.append(corr / cnt)\n",
    "        Ytrain.append(single_data)\n",
    "    with open('{}_id{}_XX.txt'.format(prefix, idx), 'r') as f:\n",
    "        single_data = []\n",
    "        for line in f:\n",
    "            for i, c in enumerate(line.split(\"\\t\")):\n",
    "                v = float(c)\n",
    "                single_data.append(v)\n",
    "        Yfull.append(single_data)\n",
    "    with open('{}_id{}_couplings.txt'.format(prefix, idx), 'r') as f:\n",
    "        single_data = []\n",
    "        for line in f:\n",
    "            for i, c in enumerate(line.split(\"\\t\")):\n",
    "                v = float(c)\n",
    "                single_data.append(v)\n",
    "        Xfull.append(single_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bee93cf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data (N) * number of params (m) = (300, 31)\n",
      "number of data (N) * number of pairs = (300, 400)\n"
     ]
    }
   ],
   "source": [
    "# Print information\n",
    "\n",
    "Xfull = np.array(Xfull)\n",
    "print(\"number of data (N) * number of params (m) =\", Xfull.shape)\n",
    "Ytrain = np.array(Ytrain)\n",
    "Yfull = np.array(Yfull)\n",
    "print(\"number of data (N) * number of pairs =\", Yfull.shape)\n",
    "\n",
    "# print(Xfull[0])\n",
    "# print(Yfull[0].reshape((length * width, length * width)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "edb26787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.05412756  0.78486598  0.67886148 -0.8011389  -0.76692495  0.04528856\n",
      " -0.65615133 -0.51053397  0.16776154  0.23954635  0.11006126  0.08825837\n",
      " -0.45139873  0.01494092 -0.04309056  0.48323862  0.76089512 -0.89362265\n",
      "  0.72244808 -0.11372986 -0.85407612 -0.62173286 -0.16480284  0.11637334\n",
      " -0.65395904  0.74126967 -0.02007992 -0.66629825 -0.20805749 -0.62617995\n",
      "  0.26462721]\n"
     ]
    }
   ],
   "source": [
    "# Normalize Xfull\n",
    "\n",
    "xmin = np.amin(Xfull)\n",
    "xmax = np.amax(Xfull)\n",
    "\n",
    "# normalize so that all entries are between -1 and 1 using min-max feature scaling\n",
    "Xfull_norm = np.array(list(map(lambda row : list(map(lambda x : -1 + 2*(x - xmin)/(xmax - xmin), row)), Xfull)))\n",
    "\n",
    "print(Xfull_norm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "abfbf14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 6), (1, 2), (2, 7), (2, 3), (3, 8), (3, 4), (4, 9), (4, 5), (5, 10), (6, 11), (6, 7), (7, 12), (7, 8), (8, 13), (8, 9), (9, 14), (9, 10), (10, 15), (11, 16), (11, 12), (12, 17), (12, 13), (13, 18), (13, 14), (14, 19), (14, 15), (15, 20), (16, 17), (17, 18), (18, 19), (19, 20)]\n"
     ]
    }
   ],
   "source": [
    "# Categorizing pairs of qubits by distance\n",
    "\n",
    "# grid of qubits\n",
    "grid = np.array(range(1, length * width + 1)).reshape((length, width))\n",
    "\n",
    "# generate all edges in grid in same order as Xfull\n",
    "all_edges = []\n",
    "for i in range(0, length):\n",
    "    for j in range(1, width + 1):\n",
    "        if i != length - 1:\n",
    "            all_edges.append((width * i + j, width * (i + 1) + j))\n",
    "        if j != width:\n",
    "            all_edges.append((width * i + j, width * i + j + 1))\n",
    "print(all_edges)\n",
    "            \n",
    "def calc_distance(q1, q2):\n",
    "    # Given two qubits q1, q2 (1-indexed integers) in length x width grid\n",
    "    # Output l1 distance between q1 and q2 in grid\n",
    "\n",
    "    pos1 = np.array(np.where(grid == q1)).T[0]\n",
    "    pos2 = np.array(np.where(grid == q2)).T[0]\n",
    "\n",
    "    return np.abs(pos1[0] - pos2[0]) + np.abs(pos1[1] - pos2[1])\n",
    "\n",
    "def get_nearby_qubit_pairs(d):\n",
    "    # Given distance d > 0\n",
    "    # Output all pairs of qubits that are within distance d of each other\n",
    "    \n",
    "    if d == 1:\n",
    "        return all_edges\n",
    "    \n",
    "    qubit_pairs = []\n",
    "    for q1 in range(1, length * width + 1):\n",
    "        for q2 in range(1, length * width + 1):\n",
    "            dist = calc_distance(q1, q2)\n",
    "            pair = tuple(sorted((q1, q2)))\n",
    "            if dist == d and pair not in qubit_pairs:\n",
    "                qubit_pairs.append(pair)\n",
    "    \n",
    "    return qubit_pairs\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9441798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding local patches of a given radius\n",
    "\n",
    "def get_local_region_qubits(q, delta1):\n",
    "    # Given a qubit q (1-indexed integer) in length x width grid and radius delta1\n",
    "    # delta1 = -1 if all qubits are in local region\n",
    "    # Output list of qubits (1-indexed integers) within a radius of delta1 of q\n",
    "    \n",
    "    if delta1 == 0:\n",
    "        return [q]\n",
    "    elif delta1 == -1:\n",
    "        return list(range(1, length * width + 1))\n",
    "    \n",
    "    local_qubits = []\n",
    "    for q2 in range(1, length * width + 1):\n",
    "        dist = calc_distance(q, q2)\n",
    "        \n",
    "        if dist <= delta1:\n",
    "            local_qubits.append(q2)\n",
    "    \n",
    "    return local_qubits\n",
    "\n",
    "def get_local_region_edges(q1, q2, delta1):\n",
    "    # Given two qubits q1, q2 (1-indexed integers) in length x width grid and radius delta1\n",
    "    # delta1 = -1 if all qubits are in local region\n",
    "    # Output list of tuples of qubits (1-indexed integers) corresponding to edges in local region of radius delta1\n",
    "\n",
    "    if delta1 == 0:\n",
    "        return [(q1, q2)]\n",
    "    elif delta1 == -1:\n",
    "        return all_edges\n",
    "\n",
    "    local_qubits = list(set(get_local_region_qubits(q1, delta1) + get_local_region_qubits(q2, delta1)))\n",
    "    \n",
    "    local_edges = []\n",
    "    for edge in all_edges:\n",
    "        (q1, q2) = edge\n",
    "        if q1 in local_qubits and q2 in local_qubits:\n",
    "            local_edges.append(edge)\n",
    "\n",
    "    return local_edges\n",
    "\n",
    "def get_local_region_params(q1, q2, delta1, data, i):\n",
    "    # Given two qubits q1, q2 (1-indexed integers) in length x width grid, radius delta1, and input data (i.e., Xfull)\n",
    "    # delta1 = -1 if all qubits are considered nearby\n",
    "    # Output data but only for parameters corresponding to edges within radius delta1\n",
    "    \n",
    "    edges = get_local_region_edges(q1, q2, delta1)\n",
    "    \n",
    "    indices = [all_edges.index(edge) for edge in edges]\n",
    "    \n",
    "    return np.array([data[i][j] for j in sorted(indices)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5c47e382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges: [(1, 6), (1, 2), (2, 7), (2, 3), (6, 7)]\n",
      "params: [ 0.05412756  0.78486598  0.67886148 -0.8011389   0.11006126]\n"
     ]
    }
   ],
   "source": [
    "print('edges: ' + str(get_local_region_edges(1,2,1)))\n",
    "print('params: ' + str(get_local_region_params(1,2,1, Xfull_norm, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5465a6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature mapping\n",
    "\n",
    "def get_feature_vectors(delta1, R, data, omega, gamma=1.0, q1=0, q2=1):\n",
    "    # Given radius delta1 and hyperparameter R (number of nonlinear features per local region), input data, and fixed randomness omega\n",
    "    # delta1 = -1 if all qubits are considered nearby\n",
    "    # Output concatenated feature vectors\n",
    "    \n",
    "    # to store all concatenated feature vectors\n",
    "    all_feature_vectors = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        feature_vector_concat = []\n",
    "        # iterate over all possible local regions\n",
    "        n = len(all_edges)\n",
    "        for k in range(n):\n",
    "            (q1, q2) = all_edges[k]\n",
    "            data_local = get_local_region_params(q1, q2, delta1, data, i)\n",
    "            m_local = len(data_local)\n",
    "\n",
    "            # do nonlinear feature map on each vector in data_local\n",
    "            feature_vector = []\n",
    "\n",
    "            for j in range(R):\n",
    "                omega_j = omega[k][j]\n",
    "                val = np.exp(np.dot(omega_j, data_local) * gamma / (m_local ** 0.5) * 1j)\n",
    "                feature_vector.append(np.real(val))\n",
    "                feature_vector.append(np.imag(val))\n",
    "\n",
    "            # concatenate feature vectors together\n",
    "            feature_vector_concat += feature_vector\n",
    "            \n",
    "        all_feature_vectors.append(feature_vector_concat)\n",
    "        \n",
    "    # note all_feature_vectors is of size number of data (N) x (2 * R * number of local regions)\n",
    "    return np.array(all_feature_vectors)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ff0fc07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(q1, q2) = (1, 6)\n",
      "(q1, q2) = (1, 2)\n",
      "(q1, q2) = (2, 7)\n",
      "(q1, q2) = (2, 3)\n",
      "(q1, q2) = (3, 8)\n",
      "(q1, q2) = (3, 4)\n",
      "(q1, q2) = (4, 9)\n",
      "(q1, q2) = (4, 5)\n",
      "(q1, q2) = (5, 10)\n",
      "(q1, q2) = (6, 11)\n",
      "(q1, q2) = (6, 7)\n",
      "(q1, q2) = (7, 12)\n",
      "(q1, q2) = (7, 8)\n",
      "(q1, q2) = (8, 13)\n",
      "(q1, q2) = (8, 9)\n",
      "(q1, q2) = (9, 14)\n",
      "(q1, q2) = (9, 10)\n",
      "(q1, q2) = (10, 15)\n",
      "(q1, q2) = (11, 16)\n",
      "(q1, q2) = (11, 12)\n",
      "(q1, q2) = (12, 17)\n",
      "(q1, q2) = (12, 13)\n",
      "(q1, q2) = (13, 18)\n",
      "(q1, q2) = (13, 14)\n",
      "(q1, q2) = (14, 19)\n",
      "(q1, q2) = (14, 15)\n",
      "(q1, q2) = (15, 20)\n",
      "(q1, q2) = (16, 17)\n",
      "(q1, q2) = (17, 18)\n",
      "(q1, q2) = (18, 19)\n",
      "(q1, q2) = (19, 20)\n",
      "(q1, q2) = (1, 3)\n",
      "(q1, q2) = (1, 7)\n",
      "(q1, q2) = (1, 11)\n",
      "(q1, q2) = (2, 4)\n",
      "(q1, q2) = (2, 6)\n",
      "(q1, q2) = (2, 8)\n",
      "(q1, q2) = (2, 12)\n",
      "(q1, q2) = (3, 5)\n",
      "(q1, q2) = (3, 7)\n",
      "(q1, q2) = (3, 9)\n",
      "(q1, q2) = (3, 13)\n",
      "(q1, q2) = (4, 8)\n",
      "(q1, q2) = (4, 10)\n",
      "(q1, q2) = (4, 14)\n",
      "(q1, q2) = (5, 9)\n",
      "(q1, q2) = (5, 15)\n",
      "(q1, q2) = (6, 8)\n",
      "(q1, q2) = (6, 12)\n",
      "(q1, q2) = (6, 16)\n",
      "(q1, q2) = (7, 9)\n",
      "(q1, q2) = (7, 11)\n",
      "(q1, q2) = (7, 13)\n",
      "(q1, q2) = (7, 17)\n",
      "(q1, q2) = (8, 10)\n",
      "(q1, q2) = (8, 12)\n",
      "(q1, q2) = (8, 14)\n",
      "(q1, q2) = (8, 18)\n",
      "(q1, q2) = (9, 13)\n",
      "(q1, q2) = (9, 15)\n",
      "(q1, q2) = (9, 19)\n",
      "(q1, q2) = (10, 14)\n",
      "(q1, q2) = (10, 20)\n",
      "(q1, q2) = (11, 13)\n",
      "(q1, q2) = (11, 17)\n",
      "(q1, q2) = (12, 14)\n",
      "(q1, q2) = (12, 16)\n",
      "(q1, q2) = (12, 18)\n",
      "(q1, q2) = (13, 15)\n",
      "(q1, q2) = (13, 17)\n",
      "(q1, q2) = (13, 19)\n",
      "(q1, q2) = (14, 18)\n",
      "(q1, q2) = (14, 20)\n",
      "(q1, q2) = (15, 19)\n",
      "(q1, q2) = (16, 18)\n",
      "(q1, q2) = (17, 19)\n",
      "(q1, q2) = (18, 20)\n",
      "(q1, q2) = (1, 4)\n",
      "(q1, q2) = (1, 8)\n",
      "(q1, q2) = (1, 12)\n",
      "(q1, q2) = (1, 16)\n",
      "(q1, q2) = (2, 5)\n",
      "(q1, q2) = (2, 9)\n",
      "(q1, q2) = (2, 11)\n",
      "(q1, q2) = (2, 13)\n",
      "(q1, q2) = (2, 17)\n",
      "(q1, q2) = (3, 6)\n",
      "(q1, q2) = (3, 10)\n",
      "(q1, q2) = (3, 12)\n",
      "(q1, q2) = (3, 14)\n",
      "(q1, q2) = (3, 18)\n",
      "(q1, q2) = (4, 7)\n",
      "(q1, q2) = (4, 13)\n",
      "(q1, q2) = (4, 15)\n",
      "(q1, q2) = (4, 19)\n",
      "(q1, q2) = (5, 8)\n",
      "(q1, q2) = (5, 14)\n",
      "(q1, q2) = (5, 20)\n",
      "(q1, q2) = (6, 9)\n",
      "(q1, q2) = (6, 13)\n",
      "(q1, q2) = (6, 17)\n",
      "(q1, q2) = (7, 10)\n",
      "(q1, q2) = (7, 14)\n",
      "(q1, q2) = (7, 16)\n",
      "(q1, q2) = (7, 18)\n",
      "(q1, q2) = (8, 11)\n",
      "(q1, q2) = (8, 15)\n",
      "(q1, q2) = (8, 17)\n",
      "(q1, q2) = (8, 19)\n",
      "(q1, q2) = (9, 12)\n",
      "(q1, q2) = (9, 18)\n",
      "(q1, q2) = (9, 20)\n",
      "(q1, q2) = (10, 13)\n",
      "(q1, q2) = (10, 19)\n",
      "(q1, q2) = (11, 14)\n",
      "(q1, q2) = (11, 18)\n",
      "(q1, q2) = (12, 15)\n",
      "(q1, q2) = (12, 19)\n",
      "(q1, q2) = (13, 16)\n",
      "(q1, q2) = (13, 20)\n",
      "(q1, q2) = (14, 17)\n",
      "(q1, q2) = (15, 18)\n",
      "(q1, q2) = (16, 19)\n",
      "(q1, q2) = (17, 20)\n"
     ]
    }
   ],
   "source": [
    "# Training and testing algorithm\n",
    "\n",
    "# set size of local region\n",
    "delta1 = 0\n",
    "\n",
    "# set max number of feature entries\n",
    "max_R = 1000\n",
    "\n",
    "# set of pairs of qubits we care about predicting correlation function for\n",
    "for d in [1, 2, 3]:\n",
    "    qubits = get_nearby_qubit_pairs(d)\n",
    "\n",
    "    # set test size\n",
    "    test_size = 0.9\n",
    "\n",
    "    train_idx, test_idx, _, _ = train_test_split(range(len(Xfull)), range(len(Xfull)), test_size=test_size, random_state=0)\n",
    "\n",
    "    # generate omega to pass into feature mapping\n",
    "    omega = []\n",
    "    for (q1, q2) in all_edges: # TODO: change this as well when changing feature mapping\n",
    "        m_local = len(get_local_region_edges(q1, q2, delta1))\n",
    "        omega_sub = []\n",
    "        for j in range(max_R):\n",
    "            omega_sub.append(np.random.normal(0, 1, m_local))\n",
    "        omega.append(omega_sub)\n",
    "\n",
    "    data_path = './clean_results/new_algorithm/test_size={}_shadow_size={}_qubits_d={}'.format(test_size, shadow_size, d)\n",
    "    with open('{}/results_{}x{}_{}_data.txt'.format(data_path, length, width, data_name), 'w') as f1, open('{}/coefficients_{}x{}_{}_data.txt'.format(data_path, length, width, data_name), 'w') as f2:\n",
    "        for (q1, q2) in qubits:\n",
    "            print('(q1, q2) =', (q1, q2))\n",
    "            print('(q1, q2) =', (q1, q2), file=f1)\n",
    "            print('(q1, q2) =', (q1, q2), file=f2)\n",
    "\n",
    "            def train_and_predict():\n",
    "                # consider the pair (q1, q2)\n",
    "                global q1, q2\n",
    "\n",
    "                # training data (estimated from measurement data)\n",
    "                y = np.array([Ytrain[i].reshape((length * width, length * width))[q1 - 1][q2 - 1] for i in range(len(Xfull))])\n",
    "                X_train, X_test, y_train, y_test = train_test_split(Xfull_norm, y, test_size=test_size, random_state=0)\n",
    "\n",
    "                # testing data (exact expectation values)\n",
    "                y_clean = np.array([Yfull[i].reshape((length * width, length * width))[q1 - 1][q2 - 1] for i in range(len(Xfull))])\n",
    "                _, _, _, y_test_clean = train_test_split(Xfull_norm, y_clean, test_size=test_size, random_state=0)\n",
    "\n",
    "                # use cross validation to find the best hyperparameters\n",
    "                best_cv_score, test_score = 999.0, 999.0\n",
    "                ML_method = lambda Cx : linear_model.Lasso(alpha=Cx, max_iter=10000)\n",
    "                best_coef = []\n",
    "                #ML_method = lambda Cx: KernelRidge(kernel='linear', alpha=Cx)\n",
    "\n",
    "                for R in [5, 10, 20, 40]:\n",
    "                    for gamma in [0.4, 0.5, 0.6, 0.65, 0.7, 0.75]:\n",
    "                        # feature mapping\n",
    "                        Xfeature_train = get_feature_vectors(delta1, R, X_train, omega, gamma, q1, q2)\n",
    "                        Xfeature_test = get_feature_vectors(delta1, R, X_test, omega, gamma, q1, q2)\n",
    "\n",
    "                        for alpha in [2**(-8), 2**(-7), 2**(-6), 2**(-5)]:\n",
    "                            score = -np.mean(cross_val_score(ML_method(alpha), Xfeature_train, y_train, cv=4, scoring=\"neg_root_mean_squared_error\"))\n",
    "                            if best_cv_score > score:\n",
    "                                clf = ML_method(alpha).fit(Xfeature_train, y_train.ravel())\n",
    "                                test_score = np.linalg.norm(clf.predict(Xfeature_test).ravel() - y_test_clean.ravel()) / (len(y_test) ** 0.5)\n",
    "                                best_cv_score = score\n",
    "                                best_coef = clf.coef_.reshape((len(all_edges), 2 * R))\n",
    "\n",
    "                                #coef = clf.coef_.reshape((len(all_edges), 2 * R))\n",
    "                                #print(list(zip(all_edges, np.linalg.norm(coef, axis=1))))\n",
    "                                #print(R, gamma, alpha, score, test_score)\n",
    "\n",
    "                coef_edges = list(zip(all_edges, np.linalg.norm(best_coef, axis=1)))\n",
    "                return best_cv_score, test_score, coef_edges\n",
    "\n",
    "            print(train_and_predict()[0:2], file=f1)\n",
    "            print(train_and_predict()[2], file=f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "21dfdfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(q1, q2) = (1, 6)\n",
      "0 0.4 0.0001220703125 0.22778087377579329 0.20181111768635496\n",
      "5 0.4 0.0001220703125 0.20254744526977436 0.14195624644832938\n",
      "5 0.4 0.000244140625 0.16831936209519216 0.12606384178245242\n",
      "5 0.4 0.00048828125 0.14759287159289125 0.10979723957682785\n",
      "5 0.4 0.0009765625 0.13853449163996046 0.09425642869705556\n",
      "5 0.4 0.001953125 0.11982115476677713 0.08770085998869379\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-56311db68e19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mbest_cv_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_coef\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_and_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_and_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-148-56311db68e19>\u001b[0m in \u001b[0;36mtrain_and_predict\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mC\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mML_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXfeature_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"neg_root_mean_squared_error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mbest_cv_score\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                             \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mML_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXfeature_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    446\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    248\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    249\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 250\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    251\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    252\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    842\u001b[0m                 \u001b[0mthis_Xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_coef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_dual_gap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_iter\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 844\u001b[0;31m                 self.path(X, y[:, k],\n\u001b[0m\u001b[1;32m    845\u001b[0m                           \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m                           \u001b[0mn_alphas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    528\u001b[0m                 tol, rng, random, positive)\n\u001b[1;32m    529\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mprecompute\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             model = cd_fast.enet_coordinate_descent(\n\u001b[0m\u001b[1;32m    531\u001b[0m                 \u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                 positive)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training and testing algorithm\n",
    "# Configured for outputting coefficients of linear model\n",
    "\n",
    "# set size of local region\n",
    "delta1 = 0\n",
    "\n",
    "# set max number of feature entries\n",
    "max_R = 1000\n",
    "\n",
    "# set of pairs of qubits we care about predicting correlation function for\n",
    "d = 1\n",
    "qubits = get_nearby_qubit_pairs(d)\n",
    "\n",
    "# set test size\n",
    "test_size = 0.4\n",
    "\n",
    "train_idx, test_idx, _, _ = train_test_split(range(len(Xfull)), range(len(Xfull)), test_size=test_size, random_state=0)\n",
    "\n",
    "# generate omega to pass into feature mapping\n",
    "omega = []\n",
    "for (q1, q2) in all_edges: # TODO: change this as well when changing feature mapping\n",
    "    m_local = len(get_local_region_edges(q1, q2, delta1))\n",
    "    omega_sub = []\n",
    "    for j in range(max_R):\n",
    "        omega_sub.append(np.random.normal(0, 1, m_local))\n",
    "    omega.append(omega_sub)\n",
    "\n",
    "with open('./results/{}_data_clf_coefficients/coefficient_{}x{}_delta1={}_local_feature_qubits{}.txt'.format(data_name, length, width, delta1, d), 'w') as f:\n",
    "    for (q1, q2) in qubits:\n",
    "        print('(q1, q2) =', (q1, q2))\n",
    "        print('(q1, q2) =', (q1, q2), file=f)\n",
    "\n",
    "        def train_and_predict():\n",
    "            # consider the pair (q1, q2)\n",
    "            global q1, q2\n",
    "\n",
    "            # training data (estimated from measurement data)\n",
    "            y = np.array([Ytrain[i].reshape((length * width, length * width))[q1 - 1][q2 - 1] for i in range(len(Xfull))])\n",
    "            X_train, X_test, y_train, y_test = train_test_split(Xfull_norm, y, test_size=test_size, random_state=0)\n",
    "\n",
    "            # testing data (exact expectation values)\n",
    "            y_clean = np.array([Yfull[i].reshape((length * width, length * width))[q1 - 1][q2 - 1] for i in range(len(Xfull))])\n",
    "            _, _, _, y_test_clean = train_test_split(Xfull_norm, y_clean, test_size=test_size, random_state=0)\n",
    "\n",
    "            # use cross validation to find the best hyperparameters\n",
    "            best_cv_score, test_score = 999.0, 999.0\n",
    "            best_coef = 0\n",
    "            ML_method = lambda Cx : linear_model.Lasso(alpha=Cx, max_iter=30000)\n",
    "            # ML_method = lambda Cx: KernelRidge(kernel='linear', alpha=Cx)\n",
    "\n",
    "            for R in [0, 5, 10, 20, 40, 80, 160, 320]:\n",
    "                for gamma in [0.4, 0.5, 0.6, 0.65, 0.7, 0.75, 1.0]:\n",
    "                    # feature mapping\n",
    "                    Xfeature_train = get_feature_vectors(delta1, R, X_train, omega, gamma, q1, q2)\n",
    "                    Xfeature_test = get_feature_vectors(delta1, R, X_test, omega, gamma, q1, q2)\n",
    "\n",
    "                    for C in [2**(-13), 2**(-12), 2**(-11), 2**(-10), 2**(-9)]:\n",
    "                        score = -np.mean(cross_val_score(ML_method(C), Xfeature_train, y_train, cv=5, scoring=\"neg_root_mean_squared_error\"))\n",
    "                        if best_cv_score > score:\n",
    "                            clf = ML_method(C).fit(Xfeature_train, y_train.ravel())\n",
    "                            test_score = np.linalg.norm(clf.predict(Xfeature_test).ravel() - y_test_clean.ravel()) / (len(y_test) ** 0.5)\n",
    "                            best_cv_score = score\n",
    "                            best_coef = clf.coef_\n",
    "    #                             print(clf.coef_)\n",
    "                            print(R, gamma, C, score, test_score)\n",
    "\n",
    "            return best_cv_score, test_score, best_coef\n",
    "\n",
    "        print(train_and_predict()[2], file=f)\n",
    "        print(train_and_predict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3b8b3d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructed Dirichlet kernel\n",
      "constructed neural tangent kernel\n",
      "RBF kernel (will be constructed in sklearn)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Dirichlet kernel\n",
    "#\n",
    "\n",
    "kernel_dir = np.zeros((len(Xfull), Xfull.shape[1]*5))\n",
    "for i, x1 in enumerate(Xfull):\n",
    "    cnt = 0\n",
    "    for k in range(len(x1)):\n",
    "        for k1 in range(-2, 3):\n",
    "            kernel_dir[i, cnt] += np.cos(np.pi * k1 * x1[k])\n",
    "            cnt += 1\n",
    "print(\"constructed Dirichlet kernel\")\n",
    "            \n",
    "#\n",
    "# Neural tangent kernel\n",
    "#\n",
    "    \n",
    "init_fn, apply_fn, kernel_fn = stax.serial(\n",
    "    stax.Dense(32), stax.Relu(),\n",
    "    stax.Dense(32), stax.Relu(),\n",
    "    stax.Dense(1)\n",
    ")\n",
    "kernel_NN2 = kernel_fn(Xfull, Xfull, 'ntk')\n",
    "\n",
    "init_fn, apply_fn, kernel_fn = stax.serial(\n",
    "    stax.Dense(32), stax.Relu(),\n",
    "    stax.Dense(32), stax.Relu(),\n",
    "    stax.Dense(32), stax.Relu(),\n",
    "    stax.Dense(1)\n",
    ")\n",
    "kernel_NN3 = kernel_fn(Xfull, Xfull, 'ntk')\n",
    "                \n",
    "init_fn, apply_fn, kernel_fn = stax.serial(\n",
    "    stax.Dense(32), stax.Relu(),\n",
    "    stax.Dense(32), stax.Relu(),\n",
    "    stax.Dense(32), stax.Relu(),\n",
    "    stax.Dense(32), stax.Relu(),\n",
    "    stax.Dense(1)\n",
    ")\n",
    "kernel_NN4 = kernel_fn(Xfull, Xfull, 'ntk')\n",
    "\n",
    "init_fn, apply_fn, kernel_fn = stax.serial(\n",
    "    stax.Dense(32), stax.Relu(),\n",
    "    stax.Dense(32), stax.Relu(),\n",
    "    stax.Dense(32), stax.Relu(),\n",
    "    stax.Dense(32), stax.Relu(),\n",
    "    stax.Dense(32), stax.Relu(),\n",
    "    stax.Dense(1)\n",
    ")\n",
    "kernel_NN5 = kernel_fn(Xfull, Xfull, 'ntk')\n",
    "\n",
    "list_kernel_NN = [kernel_NN2, kernel_NN3, kernel_NN4, kernel_NN5]\n",
    "\n",
    "for r in range(len(list_kernel_NN)):\n",
    "    kernel = list_kernel_NN[r].copy()\n",
    "    for i in range(len(list_kernel_NN[r])):\n",
    "        for j in range(len(list_kernel_NN[r])):\n",
    "            # list_kernel_NN[r][i][j] /= (list_kernel_NN[r][i][i] * list_kernel_NN[r][j][j]) ** 0.5\n",
    "            list_kernel_NN[r][i].at[j].divide((kernel[i][i] * kernel[j][j]) ** 0.5)\n",
    "print(\"constructed neural tangent kernel\")\n",
    "            \n",
    "#\n",
    "# RBF kernel is defined in Sklearn\n",
    "#\n",
    "print(\"RBF kernel (will be constructed in sklearn)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "11d497a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(q1, q2) = (4, 5)\n",
      "Dirich. kernel (0.2524725471445278, 0.24720161876210964)\n",
      "Gaussi. kernel (0.18580648811215386, 0.19334888028240627)\n",
      "Neur. T kernel (0.13558781374889525, 0.1640358656018234)\n",
      "Neur. T kernel (0.1397908436522027, 0.16704989523840308)\n",
      "Neur. T kernel (0.16193101833276144, 0.18731811705888335)\n",
      "Neur. T kernel (0.19950551325783114, 0.21130932478677994)\n"
     ]
    }
   ],
   "source": [
    "# Training and testing algorithm (Old method)\n",
    "\n",
    "# set of pairs of qubits we care about predicting correlation function for\n",
    "d = 1\n",
    "qubits = get_nearby_qubit_pairs(d)\n",
    "\n",
    "test_size = 0.4\n",
    "\n",
    "train_idx, test_idx, _, _ = train_test_split(range(len(Xfull)), range(len(Xfull)), test_size=test_size, random_state=0)\n",
    "\n",
    "#with open('./results/orig_algorithm/orig_algorithm_test_size={}/orig_algorithm_{}_data_k/results_{}x{}_all_qubits.txt'.format(test_size, data_name, length, width), 'w') as f:\n",
    "for (q1, q2) in qubits[7:8]:\n",
    "    # each k corresponds to the correlation function in a pair of qubits\n",
    "    print(\"(q1, q2) = ({}, {})\".format(q1, q2))\n",
    "    #print(\"k =\", k, file=f)\n",
    "\n",
    "    def train_and_predict(kernel, opt=\"linear\"): # opt=\"linear\" or \"rbf\"\n",
    "\n",
    "        # instance-wise normalization\n",
    "        for i in range(len(kernel)):\n",
    "            if type(kernel) == np.ndarray:\n",
    "                kernel[i] /= np.linalg.norm(kernel[i])\n",
    "            else:\n",
    "                kernel.at[i].divide(np.linalg.norm(kernel[i]))\n",
    "\n",
    "        # consider the k-th pair\n",
    "        global q1, q2\n",
    "\n",
    "        # training data (estimated from measurement data)\n",
    "        y = np.array([Ytrain[i].reshape((length * width, length * width))[q1 - 1][q2 - 1] for i in range(len(Xfull))])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(kernel, y, test_size=test_size, random_state=0)\n",
    "\n",
    "        # testing data (exact expectation values)\n",
    "        y_clean = np.array([Yfull[i].reshape((length * width, length * width))[q1 - 1][q2 - 1] for i in range(len(Xfull))])\n",
    "        _, _, _, y_test_clean = train_test_split(kernel, y_clean, test_size=test_size, random_state=0)\n",
    "\n",
    "        # use cross validation to find the best method + hyper-param\n",
    "        best_cv_score, test_score = 999.0, 999.0\n",
    "        for ML_method in [(lambda Cx: svm.SVR(kernel=opt, C=Cx)), (lambda Cx: KernelRidge(kernel=opt, alpha=1/(2*Cx)))]:\n",
    "            for C in [0.0125, 0.025, 0.05, 0.125, 0.25, 0.5, 1.0, 2.0]:\n",
    "                score = -np.mean(cross_val_score(ML_method(C), X_train, y_train, cv=5, scoring=\"neg_root_mean_squared_error\"))\n",
    "                if best_cv_score > score:\n",
    "                    clf = ML_method(C).fit(X_train, y_train.ravel())\n",
    "                    test_score = np.linalg.norm(clf.predict(X_test).ravel() - y_test_clean.ravel()) / (len(y_test) ** 0.5)\n",
    "                    best_cv_score = score\n",
    "\n",
    "        return best_cv_score, test_score\n",
    "\n",
    "    # Dirichlet\n",
    "    #print(\"Dirich. kernel\", train_and_predict(kernel_dir), file=f)\n",
    "    print(\"Dirich. kernel\", train_and_predict(kernel_dir))\n",
    "    # RBF\n",
    "    #print(\"Gaussi. kernel\", train_and_predict(Xfull, opt=\"rbf\"), file=f)\n",
    "    print(\"Gaussi. kernel\", train_and_predict(Xfull, opt=\"rbf\"))\n",
    "    # Neural tangent\n",
    "    for kernel_NN in list_kernel_NN:\n",
    "        #print(\"Neur. T kernel\", train_and_predict(kernel_NN), file=f)\n",
    "        print(\"Neur. T kernel\", train_and_predict(kernel_NN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f790a8db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
